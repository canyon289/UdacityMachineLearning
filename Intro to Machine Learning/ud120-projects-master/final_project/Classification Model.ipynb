{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful References\n",
    "* http://scikit-learn.org/stable/auto_examples/grid_search_digits.html\n",
    "* http://stackoverflow.com/questions/10317885/decision-tree-vs-naive-bayes-classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Explanation\n",
    "The goal of this project was to see if a machine learning algorithm could correctly be trained to identify people that likely commited fraud, considered \"Persons of Interest\" or \"POI\" given some information about them. For this project the data sources were generated by Katie Malone. Three primary data sources were provided.\n",
    "\n",
    "One was various financial information about numerous persons associated with Enron. This included Salary, Bonuses, Deferred stock etc. Another was the known Enron emails of most of those persons. And the last was the target, whether those people were Persons of Interest, as judged by Katie.\n",
    "\n",
    "The dataset had numerous columns but even without looking at the data it can logically be surmised that the people who commited fraud likely used it for financial gain and that studying the financial data could give a good guess as to who was aware of or commited fraduluent activity.\n",
    "\n",
    "An initial investigation was made of the data. The dataset contained 146 rows, 21 columns, and out of the 148 rows, 18 were people of interest. An initial exploration quickly showed that a Total row was present. Clearly this was of interest in the source PDF but not an actual datapoint for a machine learning algorithm. This point was quickly removed.\n",
    "\n",
    "Further analysis was then performed to get a sense of the data. All features were studied to determine the number of missing values, as well as the range and distribution for the values that were present. All details can be found in the Enron Data Exploration notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "An initial list of features were selected by hand. The first was an Engineered features named Email_bool. When investigating the missing values it was found that all the POI's had email addresses, but the not all non POIs had an email. To create this feature the email_address column was converted to an integer, 0 for missing email, 1 for email present.\n",
    "\n",
    "All other features were compared using box plots. By studying the difference between the POI values and the non POI values, features that looked like they could be use to separate the two groups were selected by hand.\n",
    "\n",
    "In addition a K Best algorithm was used with the default algorithm, which is a One Way Anova test. Essentially ANOVA calculates the percentage of variance explained by a particular variable on a predictor, known as the F Statistic.\n",
    "\n",
    "In this case the two sets of features, those selected by hand and those selected by KBest were merged to form one larger featureset.\n",
    "\n",
    "As will be further discussed below, no feature scaling was needed as a decision tree algorithm was used. I primarily chose this as I encoded the missing values from the datasets as 0s. This worked well for a decision tree, as decision trees are not affected by \"distance\" from points, as K Means and SVMs are, but rather just penalized if data points are correctly or incorrectly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "Two methods were tested, one was a Random Forest classifer, and the other was a desicion tree. Initially both models were tested by quickly guessing parameters and seeing the result. From these intial tests the decision tree seemed to show better accuracy, and subsequently lower recall and precision values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
